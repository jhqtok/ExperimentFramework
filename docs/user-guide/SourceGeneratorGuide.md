# ExperimentFramework Guide

This guide explains how to use the ExperimentFramework to implement runtime-switchable experiments in your .NET applications.

## Overview

The ExperimentFramework enables you to A/B test different implementations of the same interface without changing application code. Switch between implementations using feature flags, configuration values, or custom routing logic - all resolved at runtime with minimal overhead.

**Key Features:**
- **Compile-time code generation**: Zero-overhead proxies generated by source generators
- **Multiple selection modes**: Feature flags, configuration, variants, or sticky routing
- **Error handling policies**: Automatic fallback when experiments fail
- **Decorator pipeline**: Add cross-cutting concerns like logging and telemetry
- **AOT compatible**: Works with Native AOT compilation and trimming
- **Type-safe**: Full compile-time validation

## Quick Start

### 1. Install Package

```bash
dotnet add package ExperimentFramework
dotnet add package ExperimentFramework.Generators
```

### 2. Create Your Service Interfaces

```csharp
public interface IMyDatabase
{
    Task<string> GetDatabaseNameAsync(CancellationToken ct = default);
    Task SaveDataAsync(string data, CancellationToken ct = default);
}

public interface ITaxProvider
{
    decimal CalculateTax(decimal amount);
}
```

### 3. Implement Multiple Variants

```csharp
// Local database implementation
public class LocalDatabase : IMyDatabase
{
    public Task<string> GetDatabaseNameAsync(CancellationToken ct = default)
        => Task.FromResult("LocalDb");

    public Task SaveDataAsync(string data, CancellationToken ct = default)
    {
        // Save to local database
        return Task.CompletedTask;
    }
}

// Cloud database implementation
public class CloudDatabase : IMyDatabase
{
    public Task<string> GetDatabaseNameAsync(CancellationToken ct = default)
        => Task.FromResult("CloudDb");

    public Task SaveDataAsync(string data, CancellationToken ct = default)
    {
        // Save to cloud database
        return Task.CompletedTask;
    }
}
```

### 4. Configure Experiments

Create a composition root using **either** the attribute approach **or** the fluent API approach:

**Option A: Attribute Approach (Recommended)**

```csharp
using ExperimentFramework;

public static class ExperimentConfiguration
{
    [ExperimentCompositionRoot]
    public static ExperimentFrameworkBuilder ConfigureExperiments()
    {
        return ExperimentFrameworkBuilder.Create()
            .Define<IMyDatabase>(c => c
                .UsingFeatureFlag("UseCloudDb")
                .AddDefaultTrial<LocalDatabase>("false")
                .AddTrial<CloudDatabase>("true"))
            .Define<ITaxProvider>(c => c
                .UsingConfigurationKey("TaxProvider")
                .AddDefaultTrial<DefaultTaxProvider>("")
                .AddTrial<OkTaxProvider>("OK")
                .AddTrial<TxTaxProvider>("TX"));
    }
}
```

**Option B: Fluent API Approach**

```csharp
using ExperimentFramework;

public static class ExperimentConfiguration
{
    public static ExperimentFrameworkBuilder ConfigureExperiments()
    {
        return ExperimentFrameworkBuilder.Create()
            .Define<IMyDatabase>(c => c
                .UsingFeatureFlag("UseCloudDb")
                .AddDefaultTrial<LocalDatabase>("false")
                .AddTrial<CloudDatabase>("true"))
            .Define<ITaxProvider>(c => c
                .UsingConfigurationKey("TaxProvider")
                .AddDefaultTrial<DefaultTaxProvider>("")
                .AddTrial<OkTaxProvider>("OK")
                .AddTrial<TxTaxProvider>("TX"))
            .UseSourceGenerators(); // Fluent API marker
    }
}
```

Both approaches trigger the source generator to create optimized proxy classes at compile time. The attribute approach is recommended for clarity, but the fluent API approach works identically.

### 5. Register Services

In your application startup (Program.cs, Startup.cs, etc.):

```csharp
var builder = WebApplication.CreateBuilder(args);

// Feature management for feature flag support
builder.Services.AddFeatureManagement();

// Register concrete implementations
builder.Services.AddScoped<LocalDatabase>();
builder.Services.AddScoped<CloudDatabase>();
builder.Services.AddScoped<DefaultTaxProvider>();
builder.Services.AddScoped<OkTaxProvider>();
builder.Services.AddScoped<TxTaxProvider>();

// Register default interface implementations
builder.Services.AddScoped<IMyDatabase, LocalDatabase>();
builder.Services.AddScoped<ITaxProvider, DefaultTaxProvider>();

// Configure experiment framework
var experiments = ExperimentConfiguration.ConfigureExperiments();
builder.Services.AddExperimentFramework(experiments);

var app = builder.Build();
```

### 6. Configure Feature Flags

Add feature flags to your `appsettings.json`:

```json
{
  "FeatureManagement": {
    "UseCloudDb": true
  },
  "TaxProvider": "OK"
}
```

### 7. Use Your Services

Inject and use services normally - routing happens automatically:

```csharp
public class MyService
{
    private readonly IMyDatabase _database;
    private readonly ITaxProvider _taxProvider;

    public MyService(IMyDatabase database, ITaxProvider taxProvider)
    {
        _database = database;
        _taxProvider = taxProvider;
    }

    public async Task ProcessOrderAsync(Order order)
    {
        // Automatically routed to CloudDatabase (UseCloudDb = true)
        await _database.SaveDataAsync(order.Data);

        // Automatically routed to OkTaxProvider (TaxProvider = "OK")
        var tax = _taxProvider.CalculateTax(order.Amount);
    }
}
```

## Proxy Modes

The framework supports two proxy generation strategies:

### Source-Generated Proxies (Default, Recommended)

Compile-time code generation using Roslyn source generators:

**Advantages:**
- Near-zero overhead (<100ns per call)
- No reflection at runtime
- AOT compatible
- Full type safety

**Configuration:**
```csharp
[ExperimentCompositionRoot]
public static ExperimentFrameworkBuilder ConfigureExperiments()
{
    return ExperimentFrameworkBuilder.Create()
        .Define<IMyDatabase>(c => c
            .UsingFeatureFlag("UseCloudDb")
            .AddDefaultTrial<LocalDatabase>("false")
            .AddTrial<CloudDatabase>("true"));
    // Source generation triggered by [ExperimentCompositionRoot]
}
```

Or explicitly with fluent API:
```csharp
public static ExperimentFrameworkBuilder ConfigureExperiments()
{
    return ExperimentFrameworkBuilder.Create()
        .Define<IMyDatabase>(/* ... */)
        .UseSourceGenerators(); // Explicit marker
}
```

### Runtime Proxies (Alternative)

Dynamic proxy generation using `System.Reflection.DispatchProxy`:

**Advantages:**
- No source generator required
- Maximum debugging flexibility
- Simpler build process

**Disadvantages:**
- Higher overhead (~800ns per call)
- Reflection-based dispatch
- Not AOT compatible

**Configuration:**
```csharp
public static ExperimentFrameworkBuilder ConfigureExperiments()
{
    return ExperimentFrameworkBuilder.Create()
        .Define<IMyDatabase>(c => c
            .UsingFeatureFlag("UseCloudDb")
            .AddDefaultTrial<LocalDatabase>("false")
            .AddTrial<CloudDatabase>("true"))
        .UseDispatchProxy(); // Use runtime proxies
}
```

**When to use runtime proxies:**
- Source generators are not available in your build environment
- You need maximum debugging flexibility during development
- Performance overhead is acceptable for your use case
- You're prototyping or doing short-term experiments

**Performance Comparison:**

| Operation | Source Generated | Runtime Proxy |
|-----------|------------------|---------------|
| Proxy overhead | <100ns | ~800ns |
| Method invocation | Direct call | Reflection-based |
| Allocations | Minimal | Higher (boxing) |
| AOT compatible | Yes | No |

## How It Works

### Source Generation

The framework uses Roslyn source generators to create proxy classes at compile time:

1. **Discovery**: The generator finds methods decorated with `[ExperimentCompositionRoot]`
2. **Analysis**: Parses all `Define<T>()` calls to extract interface types and configuration
3. **Generation**: Creates optimized proxy classes implementing each interface
4. **Registration**: `AddExperimentFramework()` discovers and registers generated proxies

**Example Generated Proxy:**

For `Define<IMyDatabase>(...)`, the generator creates:

```csharp
namespace ExperimentFramework.Generated
{
    internal sealed class MyDatabaseExperimentProxy : IMyDatabase
    {
        private readonly IServiceScopeFactory _scopeFactory;
        private readonly ExperimentRegistration _registration;
        private readonly IExperimentDecoratorFactory[] _decoratorFactories;
        private readonly IExperimentTelemetry _telemetry;

        public MyDatabaseExperimentProxy(/* ... */) { /* ... */ }

        public async Task<string> GetDatabaseNameAsync(CancellationToken ct)
        {
            using var scope = _scopeFactory.CreateScope();

            // Select trial based on configuration (feature flag, config value, etc.)
            var trialKey = await SelectTrialKeyAsync(scope.ServiceProvider);

            // Determine candidates based on error policy
            var candidates = BuildCandidateKeys(trialKey);

            // Try each candidate until one succeeds
            foreach (var key in candidates)
            {
                try
                {
                    var impl = ResolveImplementation(scope.ServiceProvider, key);
                    return await impl.GetDatabaseNameAsync(ct); // Direct call!
                }
                catch when (_registration.OnErrorPolicy != OnErrorPolicy.Throw)
                {
                    // Try next candidate
                }
            }

            throw new InvalidOperationException("All trials failed");
        }
    }
}
```

### Naming Convention

Generated proxies follow a consistent naming pattern:

| Interface            | Generated Proxy                    |
|----------------------|-------------------------------------|
| `IMyDatabase`        | `MyDatabaseExperimentProxy`        |
| `ITaxProvider`       | `TaxProviderExperimentProxy`       |
| `IRepository<T>`     | `RepositoryExperimentProxy<T>`     |

**Rules:**
1. Strip 'I' prefix if followed by uppercase letter
2. Add 'ExperimentProxy' suffix
3. Preserve generic type parameters
4. Namespace: `ExperimentFramework.Generated`

## Selection Modes

The framework supports four selection modes for routing requests to trials:

### 1. Boolean Feature Flag

Routes based on a true/false feature flag using `IFeatureManager`:

```csharp
.Define<IMyDatabase>(c => c
    .UsingFeatureFlag("UseCloudDb")
    .AddDefaultTrial<LocalDatabase>("false")
    .AddTrial<CloudDatabase>("true"))
```

**Configuration:**
```json
{
  "FeatureManagement": {
    "UseCloudDb": true
  }
}
```

**Behavior:**
- `UseCloudDb = true` → Routes to `CloudDatabase`
- `UseCloudDb = false` or missing → Routes to `LocalDatabase`

### 2. Configuration Value

Routes based on any configuration value (multi-variant):

```csharp
.Define<ITaxProvider>(c => c
    .UsingConfigurationKey("TaxProvider")
    .AddDefaultTrial<DefaultTaxProvider>("")
    .AddTrial<OkTaxProvider>("OK")
    .AddTrial<TxTaxProvider>("TX"))
```

**Configuration:**
```json
{
  "TaxProvider": "TX"
}
```

**Behavior:**
- `TaxProvider = "TX"` → Routes to `TxTaxProvider`
- `TaxProvider = "OK"` → Routes to `OkTaxProvider`
- `TaxProvider = ""` or missing → Routes to `DefaultTaxProvider`

### 3. Variant Feature Flag

Routes based on variant feature flags (requires Microsoft.FeatureManagement variants):

```csharp
.Define<IRecommendationEngine>(c => c
    .UsingVariantFeatureFlag("RecommendationAlgorithm")
    .AddDefaultTrial<BasicRecommendations>("control")
    .AddTrial<MLRecommendations>("ml-powered")
    .AddTrial<HybridRecommendations>("hybrid"))
```

**Configuration:**
```json
{
  "FeatureManagement": {
    "RecommendationAlgorithm": {
      "EnabledFor": [
        {
          "Name": "Microsoft.Targeting",
          "Parameters": {
            "Audience": {
              "Users": ["user1", "user2"],
              "Groups": ["beta-testers"]
            }
          }
        }
      ],
      "Variants": [
        { "Name": "control", "Weight": 50 },
        { "Name": "ml-powered", "Weight": 30 },
        { "Name": "hybrid", "Weight": 20 }
      ]
    }
  }
}
```

### 4. Sticky Routing

Deterministic routing based on user identity (for A/B testing):

```csharp
.Define<ICheckoutFlow>(c => c
    .UsingStickyRouting()
    .AddDefaultTrial<StandardCheckout>("control")
    .AddTrial<ExpressCheckout>("variant-a")
    .AddTrial<OneClickCheckout>("variant-b"))
```

**Requirements:**
- Register an `IExperimentIdentityProvider` implementation
- Provides consistent routing for the same user

```csharp
public class UserIdentityProvider : IExperimentIdentityProvider
{
    private readonly IHttpContextAccessor _contextAccessor;

    public UserIdentityProvider(IHttpContextAccessor contextAccessor)
        => _contextAccessor = contextAccessor;

    public bool TryGetIdentity(out string identity)
    {
        identity = _contextAccessor.HttpContext?.User?.FindFirst("sub")?.Value ?? "";
        return !string.IsNullOrEmpty(identity);
    }
}

// Registration
services.AddScoped<IExperimentIdentityProvider, UserIdentityProvider>();
```

**Behavior:**
- Uses stable hashing to ensure the same user always sees the same variant
- Distributes users evenly across variants

## Error Policies

Control fallback behavior when a trial throws an exception:

### 1. Throw (No Fallback)

Immediately propagate exceptions:

```csharp
.Define<IMyService>(c => c
    .UsingFeatureFlag("UseNewImpl")
    .AddDefaultTrial<OldImpl>("false")
    .AddTrial<NewImpl>("true")
    .OnErrorThrow())
```

**Behavior:**
- If selected trial throws, the exception propagates immediately
- No fallback attempts

**Use when:**
- You want to fail fast
- Experiments are low-risk
- You prefer explicit error handling

### 2. RedirectAndReplayDefault (Safe Fallback)

Falls back to default trial if selected trial fails:

```csharp
.Define<IMyService>(c => c
    .UsingFeatureFlag("UseNewImpl")
    .AddDefaultTrial<OldImpl>("false")
    .AddTrial<NewImpl>("true")
    .OnErrorRedirectAndReplayDefault())
```

**Behavior:**
- Tries selected trial first
- If it fails and selected ≠ default, retries with default trial
- If default fails or selected = default, propagates exception

**Use when:**
- Default implementation is known to be stable
- You want graceful degradation
- Experimental trials may have bugs

### 3. RedirectAndReplayAny (Try All)

Tries all trials until one succeeds:

```csharp
.Define<ITaxProvider>(c => c
    .UsingConfigurationKey("TaxProvider")
    .AddDefaultTrial<DefaultTaxProvider>("")
    .AddTrial<OkTaxProvider>("OK")
    .AddTrial<TxTaxProvider>("TX")
    .OnErrorRedirectAndReplayAny())
```

**Behavior:**
- Tries selected trial first
- If it fails, tries default trial
- If default fails, tries remaining trials
- Only throws if all trials fail

**Use when:**
- Multiple trials are stable
- Availability is more important than consistency
- Failover across multiple backends

## Decorators

Add cross-cutting concerns to experiments without modifying implementations:

### Built-in Decorators

#### Benchmark Logging

Logs execution time for each experiment invocation:

```csharp
.AddLogger(l => l.AddBenchmarks())
```

**Output:**
```
info: ExperimentFramework.Benchmarks[0] Experiment call: IMyDatabase.GetDatabaseNameAsync trial=true elapsedMs=0.6074
```

#### Error Logging

Logs exceptions during experiment execution:

```csharp
.AddLogger(l => l.AddErrorLogging())
```

**Output:**
```
error: ExperimentFramework.Errors[0] Experiment failed: IMyDatabase.SaveDataAsync trial=true error=Connection timeout
```

#### Combined Logging

```csharp
.AddLogger(l => l.AddBenchmarks().AddErrorLogging())
```

### Custom Decorators

Implement `IExperimentDecorator` for custom behavior:

```csharp
public class CircuitBreakerDecorator : IExperimentDecorator
{
    private readonly ICircuitBreaker _circuitBreaker;

    public CircuitBreakerDecorator(ICircuitBreaker circuitBreaker)
        => _circuitBreaker = circuitBreaker;

    public async ValueTask<object?> InvokeAsync(
        InvocationContext context,
        Func<ValueTask<object?>> next)
    {
        return await _circuitBreaker.ExecuteAsync(
            () => next(),
            context.TrialKey);
    }
}

public class CircuitBreakerDecoratorFactory : IExperimentDecoratorFactory
{
    public IExperimentDecorator Create(IServiceProvider serviceProvider)
        => new CircuitBreakerDecorator(
            serviceProvider.GetRequiredService<ICircuitBreaker>());
}

// Registration
.AddDecorator(new CircuitBreakerDecoratorFactory())
```

## Telemetry

### OpenTelemetry Integration

Export experiment traces to OpenTelemetry:

```csharp
services.AddExperimentFramework(experiments);
services.AddOpenTelemetryExperimentTracking();

// Configure OpenTelemetry SDK
services.AddOpenTelemetry()
    .WithTracing(builder => builder
        .AddSource("ExperimentFramework")
        .AddConsoleExporter());
```

**Emitted Spans:**
```
Activity.TraceId:            1234567890abcdef
Activity.SpanId:             fedcba0987654321
Activity.TraceFlags:         Recorded
Activity.ActivitySourceName: ExperimentFramework
Activity.DisplayName:        IMyDatabase.GetDatabaseNameAsync
Activity.Kind:               Internal
Activity.StartTime:          2024-01-15T10:30:00Z
Activity.Duration:           00:00:00.0012345
Tags:
    experiment.service:      IMyDatabase
    experiment.method:       GetDatabaseNameAsync
    experiment.featureFlag:  UseCloudDb
    experiment.selectedTrial: true
    experiment.outcome:      success
```

## Advanced Usage

### Generic Interfaces

Generic interfaces are fully supported:

```csharp
public interface IRepository<T> where T : class
{
    Task<T?> GetByIdAsync(int id);
    Task<IEnumerable<T>> GetAllAsync();
    Task SaveAsync(T entity);
}

[ExperimentCompositionRoot]
public static ExperimentFrameworkBuilder ConfigureExperiments()
{
    return ExperimentFrameworkBuilder.Create()
        .Define<IRepository<User>>(c => c
            .UsingFeatureFlag("UseNewUserRepo")
            .AddDefaultTrial<UserRepositoryV1>("false")
            .AddTrial<UserRepositoryV2>("true"))
        .Define<IRepository<Product>>(c => c
            .UsingFeatureFlag("UseNewProductRepo")
            .AddDefaultTrial<ProductRepositoryV1>("false")
            .AddTrial<ProductRepositoryV2>("true"));
}
```

**Service Registration:**
```csharp
services.AddScoped<UserRepositoryV1>();
services.AddScoped<UserRepositoryV2>();
services.AddScoped<ProductRepositoryV1>();
services.AddScoped<ProductRepositoryV2>();

services.AddScoped<IRepository<User>, UserRepositoryV1>();
services.AddScoped<IRepository<Product>, ProductRepositoryV1>();
```

### Nullable Reference Types

The framework preserves nullable annotations:

```csharp
public interface IUserService
{
    Task<User?> FindUserAsync(int id);      // May return null
    Task<User> GetUserAsync(int id);        // Never returns null
    Task UpdateAsync(User? user);           // Accepts null
}
```

Generated proxies maintain exact nullability semantics.

### Multiple Composition Roots

Organize experiments across multiple assemblies:

```csharp
// Core.dll
public static class CoreExperiments
{
    [ExperimentCompositionRoot]
    public static ExperimentFrameworkBuilder ConfigureCoreExperiments()
    {
        return ExperimentFrameworkBuilder.Create()
            .Define<IDatabase>(/* ... */);
    }
}

// Features.dll
public static class FeatureExperiments
{
    [ExperimentCompositionRoot]
    public static ExperimentFrameworkBuilder ConfigureFeatureExperiments()
    {
        return ExperimentFrameworkBuilder.Create()
            .Define<IFeatureService>(/* ... */);
    }
}

// Startup
services.AddExperimentFramework(CoreExperiments.ConfigureCoreExperiments());
services.AddExperimentFramework(FeatureExperiments.ConfigureFeatureExperiments());
```

### Custom Naming Conventions

Override default feature flag/configuration key names:

```csharp
public class CustomNamingConvention : IExperimentNamingConvention
{
    public string FeatureFlagNameFor(Type serviceType)
        => $"Features.{serviceType.Name}";

    public string VariantFlagNameFor(Type serviceType)
        => $"Variants.{serviceType.Name}";

    public string ConfigurationKeyFor(Type serviceType)
        => $"Experiments:{serviceType.Name}";
}

// Usage
.UseNamingConvention(new CustomNamingConvention())
.Define<IMyService>(c => c
    .UsingFeatureFlag() // Uses convention: "Features.IMyService"
    .AddDefaultTrial<ServiceV1>("false")
    .AddTrial<ServiceV2>("true"))
```

## Viewing Generated Code

### Visual Studio
1. Expand "Dependencies" > "Analyzers" > "ExperimentFramework.Generators"
2. View `.g.cs` files directly in Solution Explorer

### VS Code / Rider
Generated files are in:
```
obj/Debug/netX.X/generated/ExperimentFramework.Generators/
```

### Build Output
```bash
dotnet build -v detailed | grep "ExperimentFramework.Generators"
```

## Troubleshooting

### Generator Not Running

**Symptom:** Build succeeds but no proxies generated

**Solutions:**
1. Ensure `[ExperimentCompositionRoot]` attribute is present
2. Verify generator project reference:
   ```xml
   <ProjectReference Include="...\ExperimentFramework.Generators.csproj"
                     OutputItemType="Analyzer"
                     ReferenceOutputAssembly="false" />
   ```
3. Clean and rebuild: `dotnet clean && dotnet build`
4. Check build output for generator diagnostics

### Missing Proxy Error

**Error:** "No source-generated proxy found for IMyService"

**Solutions:**
1. Verify composition root has `[ExperimentCompositionRoot]` attribute
2. Ensure `Define<IMyService>()` is in the attributed method
3. Check that IMyService is public
4. Rebuild project

### Trial Resolution Error

**Error:** "No service for type MyServiceV2"

**Solutions:**
1. Register all trial implementations:
   ```csharp
   services.AddScoped<MyServiceV1>();
   services.AddScoped<MyServiceV2>();
   ```
2. Ensure implementations are concrete classes (not interfaces)
3. Verify service lifetimes are compatible (scoped/transient work with experiments)

## Best Practices

### 1. Start Simple

Begin with feature flags for binary A/B tests:

```csharp
.Define<IMyService>(c => c
    .UsingFeatureFlag("UseNewService")
    .AddDefaultTrial<OldService>("false")
    .AddTrial<NewService>("true"))
```

Graduate to multi-variant or sticky routing as needed.

### 2. Use Safe Error Policies

Default to `RedirectAndReplayDefault()` for production experiments:

```csharp
.OnErrorRedirectAndReplayDefault()
```

Only use `Throw()` for low-risk experiments or during development.

### 3. Centralize Configuration

Keep one composition root per assembly:

```csharp
[ExperimentCompositionRoot]
public static ExperimentFrameworkBuilder ConfigureAllExperiments()
{
    return ExperimentFrameworkBuilder.Create()
        .Define<IServiceA>(/* ... */)
        .Define<IServiceB>(/* ... */)
        .Define<IServiceC>(/* ... */);
}
```

### 4. Enable Telemetry

Track experiment behavior in production:

```csharp
.AddLogger(l => l.AddBenchmarks().AddErrorLogging())

// Or OpenTelemetry for production
services.AddOpenTelemetryExperimentTracking();
```

### 5. Test Experiment Switching

Verify both trials work correctly:

```csharp
[Fact]
public async Task TestBothDatabaseImplementations()
{
    // Test with local database
    var config = new ConfigurationBuilder()
        .AddInMemoryCollection(new Dictionary<string, string>
        {
            ["FeatureManagement:UseCloudDb"] = "false"
        })
        .Build();

    var services = CreateServiceCollection(config);
    var db = services.GetRequiredService<IMyDatabase>();
    var name = await db.GetDatabaseNameAsync();
    Assert.Equal("LocalDb", name);

    // Test with cloud database
    config["FeatureManagement:UseCloudDb"] = "true";
    db = services.GetRequiredService<IMyDatabase>();
    name = await db.GetDatabaseNameAsync();
    Assert.Equal("CloudDb", name);
}
```

## Performance

The framework is designed for minimal overhead:

- **Proxy dispatch**: <100ns per call
- **Trial selection**: Cached where possible (IFeatureManagerSnapshot)
- **Scope creation**: Only for trial execution, not configuration
- **Allocations**: Minimal, primarily from scope creation

For high-throughput scenarios:
- Use `IFeatureManagerSnapshot` for request-scoped caching
- Minimize decorator count
- Prefer feature flags over configuration lookups

## Summary

The ExperimentFramework provides a clean, performant way to implement runtime-switchable experiments:

1. **Define experiments** with `[ExperimentCompositionRoot]` and `Define<T>()`
2. **Register services** with your DI container
3. **Configure routing** via feature flags or configuration
4. **Use services** normally - routing happens automatically

The source generator creates zero-overhead proxies at compile time, enabling safe, fast experimentation in production.
